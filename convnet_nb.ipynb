{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec44e8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from keras import layers, models, optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af9f3e3",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64588038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to specify where's your project directory\n",
    "# Laptop\n",
    "# pdir = '/Users/Lucas/Documents/Cours/S9 - SIIA/IML - Interactive Machine Learning/Projet_IML_Robot/Projet_IML_Robot_Detection'\n",
    "\n",
    "# Desktop computer\n",
    "pdir = '/Users/Lucas/Desktop/IML/Projet_IML_Robot'\n",
    "\n",
    "\n",
    "# The directory where you uncompressed the dogs vs cats dataset\n",
    "# Laptop\n",
    "# original_dataset_dir = '/Users/Lucas/Documents/Cours/S9 - SIIA/IML - Interactive Machine Learning/Projet_IML_Robot/kaggle_dataset_dogs_vs_cats_uncompressed/train'\n",
    "\n",
    "# Desktop computer\n",
    "original_dataset_dir = '/Users/Lucas/Desktop/kaggle_dataset_dogs_vs_cats_uncompressed/train'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6949fc93",
   "metadata": {},
   "source": [
    "### Creating directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9f3d1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where you'll store your smaller dataset\n",
    "base_dir = pdir+'data'\n",
    "if (os.path.exists(pdir+'data'))==False:\n",
    "    os.mkdir(base_dir)\n",
    "\n",
    "# Data / Train\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "if (os.path.exists(pdir+'data/train'))==False:\n",
    "    os.mkdir(train_dir)\n",
    "\n",
    "# Data / Validation\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "if (os.path.exists(pdir+'data/validation'))==False:\n",
    "    os.mkdir(validation_dir)\n",
    "\n",
    "# Data / Test\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "if (os.path.exists(pdir+'data/test'))==False:\n",
    "    os.mkdir(test_dir)\n",
    "\n",
    "# Data / Train / Cats\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "if (os.path.exists(pdir+'data/train/cats'))==False:\n",
    "    os.mkdir(train_cats_dir)\n",
    "\n",
    "# # Data / Train / Dogs\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "if (os.path.exists(pdir+'data/train/dogs'))==False:\n",
    "    os.mkdir(train_dogs_dir)\n",
    "\n",
    "# Data / Validation / Cats\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "if (os.path.exists(pdir+'data/validation/cats'))==False:\n",
    "    os.mkdir(validation_cats_dir)\n",
    "\n",
    "# Data / Validation / Dogs  \n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "if (os.path.exists(pdir+'data/validation/dogs'))==False:\n",
    "    os.mkdir(validation_dogs_dir)\n",
    "\n",
    "# Data / Test / Cats    \n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "if (os.path.exists(pdir+'data/test/cats'))==False:\n",
    "    os.mkdir(test_cats_dir)\n",
    "\n",
    "# Data / Test / Dogs   \n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "if (os.path.exists(pdir+'data/test/dogs'))==False:\n",
    "    os.mkdir(test_dogs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93c9437",
   "metadata": {},
   "source": [
    "### Copying images to training, validation, and test directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e8dcc86",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/Lucas/Desktop/kaggle_dataset_dogs_vs_cats_uncompressed/train\\\\cat.0.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11692/2412764896.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_dataset_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mdst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_cats_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopyfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'total training cat images :'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_cats_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m             \u001b[1;31m# macOS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0m_HAS_FCOPYFILE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/Lucas/Desktop/kaggle_dataset_dogs_vs_cats_uncompressed/train\\\\cat.0.jpg'"
     ]
    }
   ],
   "source": [
    "# Copy the first 6250 cat images to train_cats_dir\n",
    "if (os.path.exists(pdir+'data/train/cats/cat.1.jpg'))==False:\n",
    "    fnames = ['cat.{}.jpg'.format(i) for i in range(6250)]\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(original_dataset_dir, fname)\n",
    "        dst = os.path.join(train_cats_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "print('total training cat images :', len(os.listdir(train_cats_dir)))\n",
    "\n",
    "\n",
    "# Copy the next 500 cat images to validation_cats_dir\n",
    "if (os.path.exists(pdir+'data/validation/cats/cat.1000.jpg'))==False:\n",
    "    fnames = ['cat.{}.jpg'.format(i) for i in range(6250, 9375)]\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(original_dataset_dir, fname)\n",
    "        dst = os.path.join(validation_cats_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "print('total validation cat images :', len(os.listdir(validation_cats_dir)))\n",
    "\n",
    "\n",
    "# Copy the next 500 cat images to test_cats_dir\n",
    "if (os.path.exists(pdir+'data/test/cats/cat.1500.jpg'))==False:\n",
    "    fnames = ['cat.{}.jpg'.format(i) for i in range(9375, 12500)]\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(original_dataset_dir, fname)\n",
    "        dst = os.path.join(test_cats_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "print('total test cat images :', len(os.listdir(test_cats_dir)))\n",
    "\n",
    "\n",
    "# Copy the first 1000 dog images to train_dogs_dir\n",
    "if (os.path.exists(pdir+'data/train/dogs/dog.1.jpg'))==False:\n",
    "    fnames = ['dog.{}.jpg'.format(i) for i in range(6250)]\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(original_dataset_dir, fname)\n",
    "        dst = os.path.join(train_dogs_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "print('total training dog images :', len(os.listdir(train_dogs_dir)))\n",
    "\n",
    "\n",
    "# Copy the next 500 dog images to validation_dogs_dir\n",
    "if (os.path.exists(pdir+'data/validation/dogs/dog.1000.jpg'))==False:\n",
    "    fnames = ['dog.{}.jpg'.format(i) for i in range(6250, 9375)]\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(original_dataset_dir, fname)\n",
    "        dst = os.path.join(validation_dogs_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "print('total validation dog images :', len(os.listdir(validation_dogs_dir)))\n",
    "\n",
    "    \n",
    "# Copy the next 500 dog images to test_dogs_dir\n",
    "if (os.path.exists(pdir+'data/test/dogs/dog.1500.jpg'))==False:\n",
    "    fnames = ['dog.{}.jpg'.format(i) for i in range(9375, 12500)]\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(original_dataset_dir, fname)\n",
    "        dst = os.path.join(test_dogs_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "print('total test dog images :', len(os.listdir(test_dogs_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd19496",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bb4a75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train samples :  0\n",
      "# Validation samples :  0\n",
      "# Test samplles :  0\n",
      "Found 0 images belonging to 2 classes.\n",
      "Found 0 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "train_samples_nb = len(os.listdir(train_dogs_dir)) + len(os.listdir(train_cats_dir))\n",
    "val_samples_nb = len(os.listdir(validation_dogs_dir)) + len(os.listdir(validation_cats_dir))\n",
    "test_samples_nb = len(os.listdir(test_dogs_dir)) + len(os.listdir(test_cats_dir))\n",
    "\n",
    "print('# Train samples : ', train_samples_nb)\n",
    "print('# Validation samples : ', val_samples_nb)\n",
    "print('# Test samplles : ', test_samples_nb)\n",
    "\n",
    "\n",
    "# Data Augmentation and rescaling it\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "\n",
    "# Test/Validation data are obviously not augmented\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Generating train data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150), # Resizes the data\n",
    "    batch_size=batch_size, # Making 50-samples batches\n",
    "    class_mode='binary')\n",
    "\n",
    "# Generating validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150), \n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb001f5",
   "metadata": {},
   "source": [
    "### Instantiating a Convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80855964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# We ended the network with a single sigmoid unit, so we'll use binary crossentropy as the loss\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4), \n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe468c2",
   "metadata": {},
   "source": [
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75c0e998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 67s 269ms/step - loss: 0.6803 - acc: 0.5580 - val_loss: 0.7453 - val_acc: 0.5220\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 64s 254ms/step - loss: 0.6434 - acc: 0.6249 - val_loss: 0.6119 - val_acc: 0.6528\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 62s 249ms/step - loss: 0.6102 - acc: 0.6617 - val_loss: 0.5509 - val_acc: 0.7204\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 62s 246ms/step - loss: 0.5899 - acc: 0.6801 - val_loss: 0.5524 - val_acc: 0.7100\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 61s 245ms/step - loss: 0.5735 - acc: 0.6969 - val_loss: 0.5807 - val_acc: 0.6864\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 61s 246ms/step - loss: 0.5638 - acc: 0.7061 - val_loss: 0.5058 - val_acc: 0.7532\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 63s 251ms/step - loss: 0.5517 - acc: 0.7154 - val_loss: 0.4891 - val_acc: 0.7596\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 62s 250ms/step - loss: 0.5448 - acc: 0.7247 - val_loss: 0.4962 - val_acc: 0.7596\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 62s 249ms/step - loss: 0.5331 - acc: 0.7347 - val_loss: 0.4987 - val_acc: 0.7488\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 62s 248ms/step - loss: 0.5234 - acc: 0.7398 - val_loss: 0.4946 - val_acc: 0.7632\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 62s 248ms/step - loss: 0.5162 - acc: 0.7405 - val_loss: 0.4542 - val_acc: 0.7884\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 62s 248ms/step - loss: 0.5089 - acc: 0.7494 - val_loss: 0.4709 - val_acc: 0.7828\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 62s 246ms/step - loss: 0.5007 - acc: 0.7597 - val_loss: 0.4323 - val_acc: 0.7956\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 62s 247ms/step - loss: 0.4954 - acc: 0.7560 - val_loss: 0.4213 - val_acc: 0.8140\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 62s 246ms/step - loss: 0.4906 - acc: 0.7610 - val_loss: 0.4103 - val_acc: 0.8088\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 62s 248ms/step - loss: 0.4831 - acc: 0.7682 - val_loss: 0.4436 - val_acc: 0.7944\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 63s 250ms/step - loss: 0.4773 - acc: 0.7732 - val_loss: 0.4549 - val_acc: 0.7852\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 62s 248ms/step - loss: 0.4705 - acc: 0.7743 - val_loss: 0.4616 - val_acc: 0.7916\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 62s 248ms/step - loss: 0.4603 - acc: 0.7833 - val_loss: 0.4141 - val_acc: 0.8120\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 62s 249ms/step - loss: 0.4602 - acc: 0.7784 - val_loss: 0.4179 - val_acc: 0.8100\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 63s 254ms/step - loss: 0.4544 - acc: 0.7870 - val_loss: 0.4378 - val_acc: 0.8216\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 62s 248ms/step - loss: 0.4476 - acc: 0.7924 - val_loss: 0.4740 - val_acc: 0.7808\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 62s 248ms/step - loss: 0.4484 - acc: 0.7872 - val_loss: 0.4326 - val_acc: 0.8072\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 62s 248ms/step - loss: 0.4310 - acc: 0.7996 - val_loss: 0.3705 - val_acc: 0.8412\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 62s 249ms/step - loss: 0.4339 - acc: 0.7943 - val_loss: 0.4268 - val_acc: 0.8100\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 62s 249ms/step - loss: 0.4311 - acc: 0.8018 - val_loss: 0.4129 - val_acc: 0.8148\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 64s 256ms/step - loss: 0.4255 - acc: 0.8029 - val_loss: 0.3678 - val_acc: 0.8432\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 68s 272ms/step - loss: 0.4224 - acc: 0.8018 - val_loss: 0.4158 - val_acc: 0.7996\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 65s 262ms/step - loss: 0.4119 - acc: 0.8083 - val_loss: 0.3677 - val_acc: 0.8456\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 66s 262ms/step - loss: 0.4059 - acc: 0.8126 - val_loss: 0.3422 - val_acc: 0.8472\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 66s 262ms/step - loss: 0.4055 - acc: 0.8156 - val_loss: 0.3456 - val_acc: 0.8508\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 66s 263ms/step - loss: 0.3946 - acc: 0.8214 - val_loss: 0.3203 - val_acc: 0.8612\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.3944 - acc: 0.8185 - val_loss: 0.4115 - val_acc: 0.8244\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 64s 255ms/step - loss: 0.3957 - acc: 0.8182 - val_loss: 0.3356 - val_acc: 0.8528\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 63s 250ms/step - loss: 0.3835 - acc: 0.8285 - val_loss: 0.3536 - val_acc: 0.8472\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 62s 249ms/step - loss: 0.3805 - acc: 0.8274 - val_loss: 0.3912 - val_acc: 0.8344\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 62s 249ms/step - loss: 0.3749 - acc: 0.8342 - val_loss: 0.3573 - val_acc: 0.8348\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 62s 249ms/step - loss: 0.3770 - acc: 0.8299 - val_loss: 0.3363 - val_acc: 0.8556\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 62s 249ms/step - loss: 0.3731 - acc: 0.8306 - val_loss: 0.2980 - val_acc: 0.8700\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 63s 254ms/step - loss: 0.3641 - acc: 0.8394 - val_loss: 0.3155 - val_acc: 0.8732\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 63s 252ms/step - loss: 0.3591 - acc: 0.8436 - val_loss: 0.3266 - val_acc: 0.8612\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 63s 252ms/step - loss: 0.3577 - acc: 0.8415 - val_loss: 0.2772 - val_acc: 0.8800\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 62s 248ms/step - loss: 0.3496 - acc: 0.8468 - val_loss: 0.2991 - val_acc: 0.8664\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 62s 249ms/step - loss: 0.3450 - acc: 0.8449 - val_loss: 0.3301 - val_acc: 0.8504\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 62s 248ms/step - loss: 0.3428 - acc: 0.8525 - val_loss: 0.3167 - val_acc: 0.8692\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 62s 249ms/step - loss: 0.3483 - acc: 0.8422 - val_loss: 0.3217 - val_acc: 0.8560\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 62s 249ms/step - loss: 0.3399 - acc: 0.8513 - val_loss: 0.2996 - val_acc: 0.8784\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 63s 254ms/step - loss: 0.3382 - acc: 0.8522 - val_loss: 0.3584 - val_acc: 0.8472\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 65s 259ms/step - loss: 0.3353 - acc: 0.8557 - val_loss: 0.3469 - val_acc: 0.8528\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 65s 259ms/step - loss: 0.3268 - acc: 0.8586 - val_loss: 0.2794 - val_acc: 0.8844\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 64s 258ms/step - loss: 0.3290 - acc: 0.8598 - val_loss: 0.3263 - val_acc: 0.8560\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 63s 253ms/step - loss: 0.3256 - acc: 0.8606 - val_loss: 0.2727 - val_acc: 0.8832\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 62s 249ms/step - loss: 0.3229 - acc: 0.8596 - val_loss: 0.2845 - val_acc: 0.8728\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 62s 249ms/step - loss: 0.3154 - acc: 0.8624 - val_loss: 0.2678 - val_acc: 0.8784\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 62s 248ms/step - loss: 0.3170 - acc: 0.8634 - val_loss: 0.2872 - val_acc: 0.8732\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 64s 256ms/step - loss: 0.3051 - acc: 0.8670 - val_loss: 0.2668 - val_acc: 0.8888\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 63s 253ms/step - loss: 0.3039 - acc: 0.8703 - val_loss: 0.2395 - val_acc: 0.8988\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 62s 249ms/step - loss: 0.3101 - acc: 0.8683 - val_loss: 0.2370 - val_acc: 0.9000\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 62s 249ms/step - loss: 0.3040 - acc: 0.8688 - val_loss: 0.2552 - val_acc: 0.8836\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 62s 248ms/step - loss: 0.3033 - acc: 0.8690 - val_loss: 0.2252 - val_acc: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "250/250 [==============================] - 62s 248ms/step - loss: 0.2968 - acc: 0.8730 - val_loss: 0.2499 - val_acc: 0.8916\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 62s 248ms/step - loss: 0.2942 - acc: 0.8715 - val_loss: 0.2454 - val_acc: 0.8976\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 64s 256ms/step - loss: 0.2842 - acc: 0.8778 - val_loss: 0.2992 - val_acc: 0.8764\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.2973 - acc: 0.8726 - val_loss: 0.2944 - val_acc: 0.8752\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 66s 263ms/step - loss: 0.2910 - acc: 0.8740 - val_loss: 0.2530 - val_acc: 0.8948\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 65s 261ms/step - loss: 0.2914 - acc: 0.8723 - val_loss: 0.2545 - val_acc: 0.8876\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 65s 261ms/step - loss: 0.2864 - acc: 0.8805 - val_loss: 0.3325 - val_acc: 0.8616\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 65s 261ms/step - loss: 0.2851 - acc: 0.8766 - val_loss: 0.2834 - val_acc: 0.8800\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 65s 261ms/step - loss: 0.2869 - acc: 0.8767 - val_loss: 0.2327 - val_acc: 0.9024\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 65s 261ms/step - loss: 0.2841 - acc: 0.8774 - val_loss: 0.2568 - val_acc: 0.8912\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 65s 261ms/step - loss: 0.2683 - acc: 0.8868 - val_loss: 0.2596 - val_acc: 0.8836\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 65s 259ms/step - loss: 0.2753 - acc: 0.8827 - val_loss: 0.2299 - val_acc: 0.9020\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 65s 261ms/step - loss: 0.2755 - acc: 0.8831 - val_loss: 0.2719 - val_acc: 0.8868\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 65s 261ms/step - loss: 0.2755 - acc: 0.8843 - val_loss: 0.2620 - val_acc: 0.8828\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 62s 250ms/step - loss: 0.2694 - acc: 0.8898 - val_loss: 0.2382 - val_acc: 0.8964\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 63s 252ms/step - loss: 0.2709 - acc: 0.8827 - val_loss: 0.2251 - val_acc: 0.9008\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 63s 250ms/step - loss: 0.2712 - acc: 0.8879 - val_loss: 0.2552 - val_acc: 0.8956\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 63s 250ms/step - loss: 0.2667 - acc: 0.8851 - val_loss: 0.2484 - val_acc: 0.8964\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 63s 250ms/step - loss: 0.2663 - acc: 0.8893 - val_loss: 0.2074 - val_acc: 0.9112\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 63s 250ms/step - loss: 0.2591 - acc: 0.8906 - val_loss: 0.2288 - val_acc: 0.8996\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 62s 249ms/step - loss: 0.2581 - acc: 0.8896 - val_loss: 0.3559 - val_acc: 0.8652\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 62s 249ms/step - loss: 0.2523 - acc: 0.8940 - val_loss: 0.2229 - val_acc: 0.9076\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 62s 250ms/step - loss: 0.2571 - acc: 0.8919 - val_loss: 0.2310 - val_acc: 0.9044\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 63s 251ms/step - loss: 0.2540 - acc: 0.8922 - val_loss: 0.2378 - val_acc: 0.9008\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 63s 250ms/step - loss: 0.2504 - acc: 0.8946 - val_loss: 0.2185 - val_acc: 0.9072\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 64s 256ms/step - loss: 0.2569 - acc: 0.8954 - val_loss: 0.3104 - val_acc: 0.8772\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 63s 251ms/step - loss: 0.2549 - acc: 0.8944 - val_loss: 0.2263 - val_acc: 0.9028\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 63s 250ms/step - loss: 0.2473 - acc: 0.8970 - val_loss: 0.2639 - val_acc: 0.8940\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 62s 250ms/step - loss: 0.2586 - acc: 0.8930 - val_loss: 0.2217 - val_acc: 0.9080\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 63s 251ms/step - loss: 0.2515 - acc: 0.8943 - val_loss: 0.2050 - val_acc: 0.9164\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 63s 251ms/step - loss: 0.2504 - acc: 0.8946 - val_loss: 0.1926 - val_acc: 0.9172\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 64s 255ms/step - loss: 0.2477 - acc: 0.9005 - val_loss: 0.2005 - val_acc: 0.9136\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 65s 259ms/step - loss: 0.2386 - acc: 0.8982 - val_loss: 0.2253 - val_acc: 0.9052\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 65s 259ms/step - loss: 0.2468 - acc: 0.8962 - val_loss: 0.3173 - val_acc: 0.8696\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 63s 251ms/step - loss: 0.2453 - acc: 0.8990 - val_loss: 0.2072 - val_acc: 0.9144\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 62s 250ms/step - loss: 0.2439 - acc: 0.8978 - val_loss: 0.2232 - val_acc: 0.9128\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 63s 251ms/step - loss: 0.2474 - acc: 0.8995 - val_loss: 0.1929 - val_acc: 0.9148\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 63s 252ms/step - loss: 0.2405 - acc: 0.8978 - val_loss: 0.2046 - val_acc: 0.9176\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 63s 251ms/step - loss: 0.2372 - acc: 0.8998 - val_loss: 0.2218 - val_acc: 0.9132\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 63s 250ms/step - loss: 0.2408 - acc: 0.8966 - val_loss: 0.2199 - val_acc: 0.9088\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_samples_nb // batch_size,\n",
    "    epochs=100,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9297273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "model.save('cats_and_dogs_full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2e8aaed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6604/1099010954.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Displaying curbes of loss and accuracy during training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Displaying curbes of loss and accuracy during training\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcea917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90837a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
